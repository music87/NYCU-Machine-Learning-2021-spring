{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from HW02\n",
    "def Readfile():\n",
    "    #read binary file\n",
    "    finTrainImg = open('./dataset/train-images-idx3-ubyte',mode='rb')\n",
    "    finTrainLb = open('./dataset/train-labels-idx1-ubyte',mode='rb')\n",
    "\n",
    "    #deal with training headers\n",
    "    finTrainImg.seek(4,0) #first 4 bytes are the header of magic number = 0x00000803 which means the following data type is unsigned byte(meaning of 0x08) and there will be three dimensions(meaning of 0x03); to skip this header, we initially seek 4 bytes from the start of the train image file\n",
    "    finTrainLb.seek(8,0) #first 4 bytes are the header of magic number. second 4 bytes are the header of first dimension, number of images, which will be defined later; to skip these headers, we initially seek 8 bytes from the start of the train lable file\n",
    "    nTrainImg=int.from_bytes(finTrainImg.read(4), byteorder='big') #second 4 bytes are the header of first dimension, number of images = 0x0000ea60 = 0d60000\n",
    "    #nTrainImg=100 #delete\n",
    "    #finTrainImg.seek(4,1) #delete\n",
    "    nRow=int.from_bytes(finTrainImg.read(4), byteorder='big') #third 4 bytes are the header of second dimension, number of rows = 0x0000001c = 0d28\n",
    "    nCol=int.from_bytes(finTrainImg.read(4), byteorder='big') #forth 4 bytes are the header of third dimension, number of columns = 0x0000001c = 0d28\n",
    "    \n",
    "    #deal with training data and parse them\n",
    "    trainImg=np.zeros((nTrainImg,nRow,nCol),dtype='uint8') #there are 60000 images; each image has 28*28 pixels; each pixel's size is 1 byte, though unit8's memory size is larger than 1 byte ... it's python's drawback\n",
    "    trainLb=np.zeros(nTrainImg,dtype='uint8') #there are 60000 images, so there are also 60000 labels\n",
    "    for i in tqdm(range(nTrainImg)):\n",
    "        for j in range(nCol):\n",
    "            for k in range(nRow):\n",
    "                trainImg[i][j][k]=int.from_bytes(finTrainImg.read(1), byteorder='big') #actually, byteorder here can be either big or liitle, because there is just \"1\" byte    \n",
    "        trainLb[i]=int.from_bytes(finTrainLb.read(1), byteorder='big')\n",
    "    finTrainImg.close()\n",
    "    finTrainLb.close()\n",
    "    \n",
    "    #binning the gray level value into two bins\n",
    "    trainImg[:][trainImg[:]<=256/2]=0\n",
    "    trainImg[:][trainImg[:]>256/2]=1 #don't change the bin assignment order!!! or all the pixel value will be zero\n",
    "    return ((trainImg,trainLb),nTrainImg,nRow,nCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from HW02\n",
    "def Imagination(P,matchDict,modelParameter,done):\n",
    "    #Imagination of number\n",
    "    (fout,_,nLabel,nPixelRow,nPixelCol)=modelParameter\n",
    "    \n",
    "    for i in range(nLabel): #deal with each number imagination\n",
    "        if done: \n",
    "            print(\"labeled class: \", i,file=fout)\n",
    "            label=matchDict[i]\n",
    "        else:\n",
    "            print(\"unlabeled class: \", i,file=fout)\n",
    "            label=i\n",
    "        #mean=np.mean(P[label])\n",
    "        #P[label][P[label]<mean]=0 #can't write this, or the P will be covered...QQ\n",
    "        #P[label][P[label]>=mean]=1\n",
    "        for x in range(nPixelRow):\n",
    "            for y in range(nPixelCol):\n",
    "                print((P[label][x][y]>=0.5).astype(int),end=\" \",file=fout)\n",
    "            print(\" \",file=fout)\n",
    "        print(\"\\n\",file=fout)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from HW04 logistic regression\n",
    "def ConfusionMatrix(truth,predict,number):\n",
    "    matrix=np.zeros((2,2))\n",
    "    matrix[0,0]=np.sum((truth==number)&(predict==number)) #TP\n",
    "    matrix[0,1]=np.sum((truth==number)&(predict!=number)) #FN\n",
    "    matrix[1,0]=np.sum((truth!=number)&(predict==number)) #FP\n",
    "    matrix[1,1]=np.sum((truth!=number)&(predict!=number)) #TN\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from HW04 logistic regression\n",
    "def ConfusionMessage(fout,truth,predict):\n",
    "    for number in range(10):\n",
    "        confusionMatrix=ConfusionMatrix(truth,predict,number)\n",
    "        print(\"\\n---------------------------------------------------------------\\n\",file=fout)\n",
    "        print(\"Confusion Matrix {}: \".format(number),file=fout)\n",
    "        print(\"\\t\\tPredict number {}\\t Predict not number {}\".format(number, number),file=fout)\n",
    "        print(\"Is number {}        {:.0f}               {:.0f}       \".format(number,confusionMatrix[0,0],confusionMatrix[0,1]),file=fout)\n",
    "        print(\"Isn't number {}     {:.0f}               {:.0f}       \".format(number,confusionMatrix[1,0],confusionMatrix[1,1]),file=fout)\n",
    "        print(\"\",end=\"\\n\",file=fout)\n",
    "        sensitivity=confusionMatrix[0,0]/(confusionMatrix[0,0]+confusionMatrix[1,0]) if (confusionMatrix[0,0]+confusionMatrix[1,0])!=0 else confusionMatrix[0,0]\n",
    "        specificity=confusionMatrix[0,0]/(confusionMatrix[0,0]+confusionMatrix[0,1]) if (confusionMatrix[0,0]+confusionMatrix[0,1])!=0 else confusionMatrix[0,0]\n",
    "        print(\"Sensitivity (Successfully predict number {}): {}\".format(number,sensitivity),file=fout)\n",
    "        print(\"Specificity (Successfully predict number {}): {}\".format(number,specificity),file=fout)\n",
    "        print(\"\",end=\"\\n\",file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatchTrueLabel(predictLb,trainLb,modelParameter):\n",
    "    (_,_,nLabel,_,_)=modelParameter\n",
    "    \n",
    "    #build a table to record which fake label is more likelihood appear in true label\n",
    "    table=np.zeros((nLabel,nLabel))\n",
    "    for labelT in range(nLabel):\n",
    "        for labelP in range(nLabel):\n",
    "            table[labelT,labelP]=np.sum((trainLb==labelT)&(predictLb==labelP))\n",
    "    \n",
    "    #build dictionary to record true label to fake label\n",
    "    matchDict = {labelT:None for labelT in range(nLabel)}\n",
    "    for i in range(1, 11):\n",
    "        maxNumIdx = np.unravel_index(np.argmax(table, axis=None), table.shape) #找出最大的值所在的\"座標位置\"，它代表著最佳match\n",
    "        matchDict[maxNumIdx[0]] = maxNumIdx[1] #maxNumIdx[0] means labelT, maxNumIdx[1] means labelP\n",
    "\n",
    "        for j in range(0,10): # record the (labelT,labelP) which we has picked\n",
    "            table[maxNumIdx[0]][j] = -1 #* i\n",
    "            table[j][maxNumIdx[1]] = -1 #* i\n",
    "    \n",
    "    #clone true label\n",
    "    markPredictLb=np.zeros(nTrainImg)\n",
    "    for tLabel in range(nLabel):\n",
    "        markPredictLb[predictLb==matchDict[tLabel]]=tLabel\n",
    "        \n",
    "    return markPredictLb,matchDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMAlogOnce(trainImg,L0,P0,modelParameter):\n",
    "    (_,nTrainImg,nLabel,nPixelRow,nPixelCol)=modelParameter\n",
    "    \n",
    "    #----------Estep----------\n",
    "    #compute the normalized responsibility based on the initial model parameter\n",
    "    W=np.zeros((nLabel,len(trainImg))) #(10,60000) #version 1: no log\n",
    "    logW=np.zeros((nLabel,len(trainImg))) #(10,60000) #version 2: log\n",
    "    # 10*15 minutes, original version\n",
    "    #for img in tqdm(range(nTrainImg)):\n",
    "    #    for label in range(nLabel):\n",
    "    #        for pixelRow in range(nPixelRow):\n",
    "    #            for pixelCol in range(nPixelCol):\n",
    "    #                logW[label][img]+=np.log(L0[label].item())+trainImg[img,pixelRow,pixelCol]*np.log(P0[label,pixelRow,pixelCol])+(1-trainImg[img,pixelRow,pixelCol])*np.log(1-P0[label,pixelRow,pixelCol]) #scalar of pixel prob\n",
    "    \n",
    "    \n",
    "    # 30 seconds, vectorize 28*28 pixel\n",
    "    #for img in tqdm(range(nTrainImg)):\n",
    "    #    for label in range(nLabel):\n",
    "    #        logW[label][img]=np.log(L0[label].item())+np.sum(trainImg[img,:,:]*np.log(P0[label,:,:])+(1-trainImg[img,:,:])*np.log(1-P0[label,:,:])) #scalar of image prob\n",
    "    \n",
    "    \n",
    "    # 10 seconds, vectorize 60000 img\n",
    "    minNum=1e-10 # to avoid error of log(0)\n",
    "    for label in range(nLabel):\n",
    "        #version 1: no log\n",
    "        dataPixelProb=(trainImg[:,:,:]*P0[label,:,:]+(1-trainImg[:,:,:])*(1-P0[label,:,:])) #no log version (60000, 28, 28)\n",
    "        W[label,:]=L0[label].item()*np.prod(dataPixelProb,axis=(1,2)) #no log version\n",
    "        #version 2: log\n",
    "        #dataPixelLogProb=trainImg[:,:,:]*np.log10(np.maximum(P0[label,:,:],minNum))+(1-trainImg[:,:,:])*np.log10(np.maximum(1-P0[label,:,:],minNum)) #log version which avoids error of log(0) version (60000, 28, 28)\n",
    "        #logW[label,:]=np.log10(np.maximum(L0[label].item(),minNum))+np.sum(dataPixelLogProb,axis=(1,2)) #sum up 28*28 pixel values => (60000,)\n",
    "    \n",
    "    # take a look at the prediced classes\n",
    "    key,value=np.unique(np.argmax(W,axis=0),return_counts=True) \n",
    "    print(dict(zip(key,value))) #np.vstack((key, value)).T\n",
    "    #key,value=np.unique(np.argmax(logW,axis=0),return_counts=True) \n",
    "    #print(dict(zip(key,value))) #np.vstack((key, value)).T\n",
    "    \n",
    "    #normalize\n",
    "    #version 1: no log\n",
    "    sums=np.sum(W,axis=0) #divide by the sum of 10 labels: (10,60000) / (60000,) => (10,60000)\n",
    "    sums[sums==0]=1 #to avoid divide by zero\n",
    "    normW_1=W/sums #no log version\n",
    "    #version 2: log\n",
    "    #scaleLogW=((logW-np.min(logW)) / (np.max(logW)-np.min(logW))) * (1-minNum) + minNum #scale negative value to positive value to avoid dividing by negative value or zero ((Input - InputLow) / (InputHigh - InputLow)) * (OutputHigh - OutputLow) + OutputLow, https://stackoverflow.com/questions/51464638/what-is-the-proper-way-to-normalize-negative-values/51464692\n",
    "    #normW_2=np.exp(scaleLogW)/np.sum(np.exp(scaleLogW),axis=0)\n",
    "    \n",
    "    #----------Mstep----------\n",
    "    #update the model parameter based on the normlized responsibility\n",
    "    #version 1: no log\n",
    "    L1_1=(np.sum(normW_1,axis=1)/nTrainImg).reshape(-1,1) #(the sum of 60000 data / 60000).reshape(-1,1): (10,60000) => (10,1) \n",
    "    #version 2: log\n",
    "    #L1_2=(np.sum(normW_2,axis=1)/nTrainImg).reshape(-1,1)\n",
    "    #print(np.argsort(L1_1.reshape(-1)))\n",
    "    print(L1_1.reshape(-1))\n",
    "    print(np.sum(L1_1))\n",
    "    \n",
    "    #version 1: no log\n",
    "    sums=np.sum(normW_1,axis=1) #P will sum up each probability of data, so we normalize all the data\n",
    "    sums[sums==0]=1 #to avoid divide by zero\n",
    "    normW_1=(normW_1.T/sums).T \n",
    "    #version 2: log\n",
    "    #normW_2=(normW_2.T/np.sum(normW_2,axis=1)).T\n",
    "    \n",
    "    #version 1: no log\n",
    "    P1_1=np.einsum('ab,bcd -> acd', normW_1, trainImg) #(10,60000) * (60000,28,28) => (10,28,28); https://stackoverflow.com/questions/58588378/how-to-matrix-multiply-a-2d-numpy-array-with-a-3d-array-to-give-a-3d-array\n",
    "                                                      #another way to update P1: P1=(normLogW@trainImg.reshape(nTrainImg,nPixelRow*nPixelCol)).reshape(nLabel,nPixelRow,nPixelCol)\n",
    "    #version 2: log\n",
    "    #P1_2=np.einsum('ab,bcd -> acd', normW_2, trainImg)\n",
    "    \n",
    "    return L1_1,P1_1,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:03<00:00, 949.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 51841, 2: 1957, 3: 902, 4: 6, 5: 1, 6: 12, 8: 5183, 9: 98}\n",
      "[1.97501863e-01 0.00000000e+00 3.25712746e-02 1.51602207e-02\n",
      " 9.45736797e-05 1.66666667e-05 2.08369672e-04 0.00000000e+00\n",
      " 8.67250016e-02 1.63869667e-03]\n",
      "0.33391666666666664\n",
      "No. of Iteration: 0, Difference: 3398.7040603857245\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 32090, 2: 5659, 3: 4967, 4: 93, 5: 1, 6: 253, 8: 14871, 9: 2066}\n",
      "[5.33731134e-01 0.00000000e+00 9.40337335e-02 8.30249265e-02\n",
      " 1.55455024e-03 1.66666667e-05 4.25502587e-03 0.00000000e+00\n",
      " 2.48340642e-01 3.44766544e-02]\n",
      "0.9994333333333332\n",
      "No. of Iteration: 1, Difference: 219.34011375627367\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 29799, 2: 5199, 3: 7194, 4: 140, 5: 1, 6: 460, 8: 14574, 9: 2633}\n",
      "[4.95917765e-01 0.00000000e+00 8.65827874e-02 1.19617264e-01\n",
      " 3.13093087e-03 1.66666667e-05 7.68196006e-03 0.00000000e+00\n",
      " 2.42556183e-01 4.39297762e-02]\n",
      "0.9994333333333334\n",
      "No. of Iteration: 2, Difference: 76.63843574234944\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 28123, 2: 5404, 3: 8451, 4: 369, 5: 1, 6: 498, 8: 14294, 9: 2860}\n",
      "[4.68052343e-01 0.00000000e+00 9.01013202e-02 1.40998896e-01\n",
      " 6.15763946e-03 1.66666667e-05 8.28398335e-03 0.00000000e+00\n",
      " 2.38236582e-01 4.75859020e-02]\n",
      "0.9994333333333334\n",
      "No. of Iteration: 3, Difference: 44.701190406229735\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 27021, 2: 6047, 3: 9138, 4: 413, 5: 1, 6: 505, 8: 13851, 9: 3024}\n",
      "[4.49856538e-01 0.00000000e+00 1.00886638e-01 1.52491924e-01\n",
      " 6.87438305e-03 1.66666667e-05 8.42079753e-03 0.00000000e+00\n",
      " 2.30538166e-01 5.03482211e-02]\n",
      "0.9994333333333334\n",
      "No. of Iteration: 4, Difference: 29.63418623234407\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 26311, 2: 7051, 3: 9445, 4: 414, 5: 1, 6: 510, 8: 13070, 9: 3198}\n",
      "[4.37802464e-01 0.00000000e+00 1.17625439e-01 1.57314816e-01\n",
      " 6.89268731e-03 1.66666667e-05 8.49244145e-03 0.00000000e+00\n",
      " 2.17984741e-01 5.33040783e-02]\n",
      "0.9994333333333335\n",
      "No. of Iteration: 5, Difference: 24.34994108275309\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 25698, 2: 8038, 3: 9506, 4: 413, 5: 1, 6: 509, 8: 12420, 9: 3415}\n",
      "[4.27505466e-01 0.00000000e+00 1.33933040e-01 1.58468247e-01\n",
      " 6.88495699e-03 1.66666667e-05 8.48401040e-03 0.00000000e+00\n",
      " 2.07223787e-01 5.69171597e-02]\n",
      "0.9994333333333333\n",
      "No. of Iteration: 6, Difference: 21.58687462334528\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 25015, 2: 9010, 3: 9488, 4: 413, 5: 1, 6: 511, 8: 11908, 9: 3654}\n",
      "[4.16285492e-01 0.00000000e+00 1.50188259e-01 1.58118788e-01\n",
      " 6.87770954e-03 1.66666667e-05 8.52952344e-03 0.00000000e+00\n",
      " 1.98497667e-01 6.09192291e-02]\n",
      "0.9994333333333334\n",
      "No. of Iteration: 7, Difference: 20.76420400854848\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 24170, 2: 9914, 3: 9476, 4: 417, 5: 1, 6: 518, 8: 11654, 9: 3850}\n",
      "[4.02178312e-01 0.00000000e+00 1.65363633e-01 1.57921157e-01\n",
      " 6.93745261e-03 1.66666667e-05 8.63912785e-03 0.00000000e+00\n",
      " 1.94150814e-01 6.42261706e-02]\n",
      "0.9994333333333333\n",
      "No. of Iteration: 8, Difference: 17.006639274885394\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 23211, 2: 10748, 3: 9492, 4: 418, 5: 1, 6: 524, 8: 11585, 9: 4021}\n",
      "[3.85952996e-01 0.00000000e+00 1.79479823e-01 1.58137112e-01\n",
      " 6.96375237e-03 1.66666667e-05 8.71277374e-03 0.00000000e+00\n",
      " 1.93109606e-01 6.70606040e-02]\n",
      "0.9994333333333334\n",
      "No. of Iteration: 9, Difference: 13.94334800915379\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 22218, 2: 11500, 3: 9541, 4: 419, 5: 1, 6: 527, 8: 11612, 9: 4182}\n",
      "[3.69512133e-01 0.00000000e+00 1.91817831e-01 1.59048182e-01\n",
      " 6.98468747e-03 1.66666667e-05 8.75535085e-03 0.00000000e+00\n",
      " 1.93699742e-01 6.95987404e-02]\n",
      "0.9994333333333334\n",
      "No. of Iteration: 10, Difference: 12.731737279424827\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 21271, 2: 12155, 3: 9644, 4: 420, 5: 1, 6: 528, 8: 11688, 9: 4293}\n",
      "[3.53951616e-01 0.00000000e+00 2.02553039e-01 1.60672554e-01\n",
      " 6.99465249e-03 1.66666667e-05 8.78823152e-03 0.00000000e+00\n",
      " 1.94956281e-01 7.15002934e-02]\n",
      "0.9994333333333334\n",
      "No. of Iteration: 11, Difference: 11.637037656929902\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 20397, 2: 12738, 3: 9779, 4: 420, 5: 1, 6: 528, 8: 11756, 9: 4381}\n",
      "[3.39117172e-01 0.00000000e+00 2.12486481e-01 1.62847860e-01\n",
      " 6.99880813e-03 1.66666667e-05 8.79563886e-03 0.00000000e+00\n",
      " 1.96065546e-01 7.31051607e-02]\n",
      "0.9994333333333334\n",
      "No. of Iteration: 12, Difference: 11.410676689998926\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 19582, 2: 13239, 3: 9953, 4: 420, 5: 1, 6: 531, 8: 11791, 9: 4483}\n",
      "[3.25336981e-01 0.00000000e+00 2.20959900e-01 1.65867292e-01\n",
      " 7.00125920e-03 1.66666667e-05 8.84152637e-03 0.00000000e+00\n",
      " 1.96802234e-01 7.46074740e-02]\n",
      "0.9994333333333334\n",
      "No. of Iteration: 13, Difference: 12.081528197167286\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 18806, 2: 13735, 3: 10168, 4: 420, 5: 1, 6: 533, 8: 11781, 9: 4556}\n",
      "[3.12364623e-01 0.00000000e+00 2.29227099e-01 1.69412374e-01\n",
      " 7.00427535e-03 1.66666667e-05 8.87521170e-03 0.00000000e+00\n",
      " 1.96630404e-01 7.59026793e-02]\n",
      "0.9994333333333333\n",
      "No. of Iteration: 14, Difference: 12.612167002237632\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 17942, 2: 14309, 3: 10415, 4: 420, 5: 1, 6: 539, 8: 11757, 9: 4617}\n",
      "[2.98411778e-01 0.00000000e+00 2.38704992e-01 1.73513012e-01\n",
      " 7.01285640e-03 1.66666667e-05 8.94487362e-03 0.00000000e+00\n",
      " 1.95784423e-01 7.70447317e-02]\n",
      "0.9994333333333332\n",
      "No. of Iteration: 15, Difference: 14.708422869423638\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 17022, 2: 14973, 3: 10646, 4: 421, 5: 1, 6: 546, 8: 11708, 9: 4683}\n",
      "[2.83156768e-01 0.00000000e+00 2.49540130e-01 1.77371510e-01\n",
      " 7.02167907e-03 1.66666667e-05 9.08491534e-03 0.00000000e+00\n",
      " 1.95117590e-01 7.81240751e-02]\n",
      "0.9994333333333334\n",
      "No. of Iteration: 16, Difference: 17.57261096129176\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 16181, 2: 15571, 3: 10872, 4: 421, 5: 1, 6: 564, 8: 11667, 9: 4723}\n",
      "[2.69152677e-01 0.00000000e+00 2.59362722e-01 1.81200012e-01\n",
      " 7.04194631e-03 1.66666667e-05 9.38955037e-03 0.00000000e+00\n",
      " 1.94400644e-01 7.88691149e-02]\n",
      "0.9994333333333332\n",
      "No. of Iteration: 17, Difference: 19.510872240938472\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 16039, 2: 15497, 3: 11108, 4: 424, 5: 1, 6: 587, 8: 11589, 9: 4755}\n",
      "[2.66561148e-01 0.00000000e+00 2.58342064e-01 1.85196398e-01\n",
      " 7.07020486e-03 1.66666667e-05 9.75949730e-03 0.00000000e+00\n",
      " 1.93171326e-01 7.93160279e-02]\n",
      "0.9994333333333334\n",
      "No. of Iteration: 18, Difference: 14.20251715265151\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 16167, 2: 15169, 3: 11306, 4: 426, 5: 1, 6: 615, 8: 11553, 9: 4763}\n",
      "[2.68807480e-01 0.00000000e+00 2.53025608e-01 1.88397074e-01\n",
      " 7.09001441e-03 1.66666667e-05 1.02838600e-02 0.00000000e+00\n",
      " 1.92396769e-01 7.94158619e-02]\n",
      "0.9994333333333333\n",
      "No. of Iteration: 19, Difference: 10.743624466189129\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "{0: 16345, 2: 14832, 3: 11458, 4: 428, 5: 1, 6: 652, 8: 11526, 9: 4758}\n",
      "[2.71818514e-01 0.00000000e+00 2.47322743e-01 1.90876893e-01\n",
      " 7.12716637e-03 1.66666667e-05 1.08858389e-02 0.00000000e+00\n",
      " 1.92075565e-01 7.93099470e-02]\n",
      "0.9994333333333332\n",
      "No. of Iteration: 20, Difference: 8.879521734517052\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    #read file and deal with the bin value\n",
    "    ((trainImg,trainLb),nTrainImg,nPixelRow,nPixelCol)=Readfile()\n",
    "    \n",
    "    #initialize model parameter\n",
    "    fout=open('./dataset/out_Imagination.txt',mode='w')#sys.stdout#\n",
    "    nLabel=10\n",
    "    eps=10\n",
    "    modelParameter=(fout,nTrainImg,nLabel,nPixelRow,nPixelCol)\n",
    "    L0=np.full((nLabel,1),1/nLabel) #assume fair #np.random.rand(nLabel,1)\n",
    "    P0=np.random.rand(nLabel,nPixelRow,nPixelCol) #assume fair bernoulli #np.full((nLabel,nPixelRow,nPixelCol),1/2)\n",
    "    diff0,diff1=1000,1000\n",
    "    done=False\n",
    "    iteration=0\n",
    "    while True:\n",
    "        #EM algorithm\n",
    "        L1,P1,logW=EMAlogOnce(trainImg,L0,P0,modelParameter)\n",
    "        #print message and image\n",
    "        diff0=diff1\n",
    "        #version 1: no log\n",
    "        diff1=np.sum(np.abs(L1-L0))+np.sum(np.abs(P1-P0))\n",
    "        #version 2: log\n",
    "        #diff1=np.sum(np.abs(np.log10(np.maximum(L1,1e-10))-np.log10(np.maximum(L0,1e-10))))+np.sum(np.abs(np.log10(np.maximum(P1,1e-10))-np.log10(np.maximum(P0,1e-10))))\n",
    "        Imagination(P1,None,modelParameter,done)\n",
    "        print(\"No. of Iteration: {}, Difference: {}\\n\".format(iteration, diff1))\n",
    "        print(\"---------------------------------------------------------------\\n\")\n",
    "        print(\"No. of Iteration: {}, Difference: {}\\n\".format(iteration, diff1),file=fout)\n",
    "        print(\"---------------------------------------------------------------\\n\",file=fout)\n",
    "        \n",
    "        #determine whether to terminate\n",
    "        if diff1<eps and (diff0-diff1)<eps:\n",
    "            done=True\n",
    "            break\n",
    "        L0=L1\n",
    "        P0=P1\n",
    "        iteration+=1\n",
    "    \n",
    "    #turn unlabeled clustering into labeled clustering based on the training labels, (train label:predict label)\n",
    "    predictLb=np.argmax(logW,axis=0)\n",
    "    mkPredictLb,matchDict=MatchTrueLabel(predictLb,trainLb,modelParameter) #or can use another matching method : https://www.dlology.com/blog/how-to-do-unsupervised-clustering-with-keras/\n",
    "    \n",
    "    #print imagination\n",
    "    Imagination(P1,matchDict,modelParameter,done)\n",
    "    \n",
    "    #print message\n",
    "    ConfusionMessage(fout,trainLb,mkPredictLb)\n",
    "    print(\"\\nTotal iteration to converge: {}\".format(iteration),file=fout)\n",
    "    print(\"Total error rate: {}\".format(np.sum(trainLb!=mkPredictLb)/nTrainImg),file=fout)\n",
    "    \n",
    "    fout.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.sum(normW_1,axis=1)/nTrainImg)\n",
    "#數量級\n",
    "(Pdb)  (np.min(W),np.max(W))\n",
    "(0.0, 1.0234446623722119e-290)\n",
    "(Pdb)  (np.min(logW),np.max(logW))\n",
    "(-387.086643795816, -289.98993563465865)\n",
    "(Pdb)  (np.min(scaleLogW),np.max(scaleLogW))\n",
    "(1e-10, 1.0)\n",
    "#----\n",
    "(Pdb)  (np.max(L1_1)-np.min(L1_1))\n",
    "0.48968515325191053 -> 0.03975004604280337\n",
    "(Pdb)  (np.max(L1_2)-np.min(L1_2))\n",
    "0.03487774247510214 -> 0.00010147601927713856 #L1_1跟L1_2差得有點多(1e-3倍), 看來normalization with exponential並沒有讓數量級回復正常\n",
    "(Pdb)  (np.max(P1_1)-np.min(P1_1))\n",
    "1.0000000000000004\n",
    "(Pdb)  (np.max(P1_2)-np.min(P1_2))\n",
    "0.5655717808179428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
